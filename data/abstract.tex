% !TeX root = ../thuthesis-example.tex

% 中英文摘要和关键字

\begin{abstract}
  随着深度学习模型规模的指数级增长，稀疏激活的混合专家（MoE）模型架构再次受到了迅速的关注。混合专家模型利用条件计算技术，可以在扩大规模规模的同时，使其训练所需计算量（FLOPs）以次线性的速度增长。随着AI计算进入到百亿亿次时代，MoE层正在逐渐成为深度神经网络（DNNs）的重要组成部分，许多相关研究团队已经投入了大量的资源来建设高效MoE模型训练系统。近期，许多MoE模型被陆续发布，比如Switch-C，这次世界上首个公开发布的万亿参数模型。尽管MoE模型的训练受到了广泛关注，但目前对其推理的研究较少。本研究提出了一个名为 ExpertFlow 的高效低延迟MoE推理系统。该框架支持多GPU和多节点的分布式推理，并且基于纯异步任务调用方式实现。实验表明，相比于英伟达提出的FasterTransformer框架，ExpertFlow可以实现1.95倍的吞吐率，平均延迟可以降低13\%。为了推广MoE模型的使用，我们开源了ExperFlow系统的全部代码：\url{https://github.com/flexflow/FlexFlow/tree/inference}。

  % 关键词用“英文逗号”分隔，输出时会自动处理为正确的分隔符
  \thusetup{
    keywords = {混合专家，Transformer，模型推理，分布式系统，异步任务 },
  }
\end{abstract}

\begin{abstract*}
  The exponential growth in the size of deep learning models has led to a burgeoning interest in the sparsely activated Mixture of Expert (MoE) model architecture. MoE uses conditional computation to scale the model size with a sub-linear growth in the corresponding number of computations (FLOPs) needed to train it. As AI computation enter the exascale computing era, the MoE layer is becoming a key component of deep neural networks (DNNs), and several research teams have dedicated significant resources to building eﬀicient MoE training systems. Recently, many MoE models have been released, including Switch-C, which is the first open-source trillion-parameters model in the world.
Although much attention has been given to MoE training, there has been less research on inference. In this thesis, we present ExpertFlow, a low-latency system for eﬀicient inference of MoE models. The framework supports multi-GPU and multi-node distributed inference and is implemented by a fully asynchronous task scheduling manner. We compare ExpertFlow to NVIDIA’s FasterTransformer framework in our experiments and find that it achieves up to 1.95x higher throughput and up to 13\% lower latency on average.
Our goal is to make the MoE architecture more accessible, and we have open-sourced all of our code at \url{https://github.com/flexflow/FlexFlow/tree/inference}.

  % Use comma as separator when inputting
  \thusetup{
    keywords* = {Mixture of Experts; Transformer; Inference; Distributed System; Asynchronous Tasks},
  }
\end{abstract*}
